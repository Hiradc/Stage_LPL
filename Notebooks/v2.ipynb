{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b44697",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mistralai import Mistral\n",
    "from google import genai\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb6e487",
   "metadata": {},
   "outputs": [],
   "source": [
    "#R√©solution du label vers l'identifiant Wikidata\n",
    "def get_wikidata_id(label: str, lang=\"en\") -> str:\n",
    "    endpoint = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
    "    query = f\"\"\"\n",
    "    SELECT ?item WHERE {{\n",
    "      ?item rdfs:label \"{label}\"@{lang} .\n",
    "    }} LIMIT 1\n",
    "    \"\"\"\n",
    "    endpoint.setQuery(query)\n",
    "    endpoint.setReturnFormat(JSON)\n",
    "    results = endpoint.query().convert()\n",
    "    bindings = results[\"results\"][\"bindings\"]\n",
    "    return bindings[0][\"item\"][\"value\"].split(\"/\")[-1] if bindings else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d902cbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recherche de chemins RDF entre deux entit√©s\n",
    "def get_semantic_paths(term1: str, term2: str, lang=\"en\", max_results=None):\n",
    "    id1 = get_wikidata_id(term1, lang)\n",
    "    id2 = get_wikidata_id(term2, lang)\n",
    "\n",
    "    if not id1 or not id2:\n",
    "        raise ValueError(\"Un ou les deux termes n'ont pas pu √™tre trouv√©s sur Wikidata.\")\n",
    "\n",
    "    print(f\"üîé R√©solution des entit√©s : '{term1}' ‚Üí {id1}, '{term2}' ‚Üí {id2}\")\n",
    "\n",
    "    endpoint = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
    "    limit_clause = f\"LIMIT {max_results}\" if max_results else \"\"\n",
    "\n",
    "    query = f\"\"\"\n",
    "    SELECT ?step1Label ?rel1Label ?step2Label ?rel2Label ?step3Label ?rel3Label ?step4Label ?rel4Label ?step5Label WHERE {{\n",
    "      wd:{id1} ?p1 ?step1 .\n",
    "      ?rel1 wikibase:directClaim ?p1 .\n",
    "      ?step1 ?p2 ?step2 .\n",
    "      ?rel2 wikibase:directClaim ?p2 .\n",
    "      ?step2 ?p3 ?step3 .\n",
    "      ?rel3 wikibase:directClaim ?p3 .\n",
    "      ?step3 ?p4 ?step4 .\n",
    "      ?rel4 wikibase:directClaim ?p4 .\n",
    "      ?step4 ?p5 wd:{id2} .\n",
    "\n",
    "      SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"{lang}\" . }}\n",
    "    }}\n",
    "    {limit_clause}\n",
    "    \"\"\"\n",
    "    endpoint.setQuery(query)\n",
    "    endpoint.setReturnFormat(JSON)\n",
    "    results = endpoint.query().convert()\n",
    "\n",
    "    chains = []\n",
    "    for res in results[\"results\"][\"bindings\"]:\n",
    "        try:\n",
    "            path = [\n",
    "                term1,\n",
    "                \"‚Üí\", res[\"rel1Label\"][\"value\"],\n",
    "                \"‚Üí\", res[\"step1Label\"][\"value\"],\n",
    "                \"‚Üí\", res[\"rel2Label\"][\"value\"],\n",
    "                \"‚Üí\", res[\"step2Label\"][\"value\"],\n",
    "                \"‚Üí\", res[\"rel3Label\"][\"value\"],\n",
    "                \"‚Üí\", res[\"step3Label\"][\"value\"],\n",
    "                \"‚Üí\", res[\"rel4Label\"][\"value\"],\n",
    "                \"‚Üí\", res[\"step4Label\"][\"value\"],\n",
    "                \"‚Üí\", term2\n",
    "            ]\n",
    "            chains.append(\" \".join(path))\n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "    return chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad40e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interface utilisateur CLI\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üåç Recherche de chemin s√©mantique entre deux concepts via Wikidata\")\n",
    "    concept1 = input(\"üìù Entrez le premier concept : \")\n",
    "    concept2 = input(\"üìù Entrez le second concept : \")\n",
    "\n",
    "    use_limit = input(\"Souhaitez-vous fixer un nombre maximal de r√©sultats ? (y/n) : \").strip().lower()\n",
    "    max_results = int(input(\"üî¢ Nombre maximal de r√©sultats √† retourner : \")) if use_limit == \"y\" else None\n",
    "\n",
    "    try:\n",
    "        chemins = get_semantic_paths(concept1, concept2, lang=\"en\", max_results=max_results)\n",
    "        if not chemins:\n",
    "            print(\"‚ùå Aucun chemin trouv√©.\")\n",
    "        else:\n",
    "            print(f\"\\nüîó {len(chemins)} chemin(s) trouv√©(s) :\")\n",
    "            for chemin in chemins:\n",
    "                print(chemin)\n",
    "    except Exception as e:\n",
    "        print(\"‚ùó Erreur :\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a648da11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choix invalide, veuillez r√©essayer.\n",
      "Choix invalide, veuillez r√©essayer.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Mistral' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m LLM = \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28minput\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mChoisissez le LLM √† utiliser (1 pour Mistral, 2 pour Google GenAI) : \u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m LLM == \u001b[32m1\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     mistral = \u001b[43mMistral\u001b[49m(api_key=\u001b[33m\"\u001b[39m\u001b[33mZzROxj7Fuf63vP41wYOtCyNM95Gijq86\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mVous avez choisi Mistral.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m LLM == \u001b[32m2\u001b[39m:\n",
      "\u001b[31mNameError\u001b[39m: name 'Mistral' is not defined"
     ]
    }
   ],
   "source": [
    "#choix du LLM\n",
    "client = None\n",
    "LLM = 1\n",
    "while LLM != 1 or LLM != 2:\n",
    "    LLM = int(input(\"Choisissez le LLM √† utiliser (1 pour Mistral, 2 pour Google GenAI) : \"))\n",
    "    if LLM == 1:\n",
    "        client = Mistral(api_key=\"ZzROxj7Fuf63vP41wYOtCyNM95Gijq86\")\n",
    "        print(\"Vous avez choisi Mistral.\")\n",
    "    elif LLM == 2:\n",
    "        client = genai.Client(api_key=\"AIzaSyBdvS09hwQXqAnLZslWe6kji0YLPXTDiX4\")\n",
    "        print(\"Vous avez choisi Gemini.\")\n",
    "    else:\n",
    "        print(\"Choix invalide, veuillez r√©essayer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d8a84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ontologist = f\"\"\"You are a sophisticated ontologist trained in scientific research, engineering, and innovation. \n",
    "    \n",
    "Given the following key concepts extracted from a comprehensive knowledge graph, your task is to define each one of the terms and discuss the relationships identified in the graph.\n",
    "\n",
    "Consider this list of nodes and relationships from a knowledge graph between \"{concept1}\" and \"{concept2}\". \n",
    "\n",
    "The format of the knowledge graph is \"node_1 -- relationship between node_1 and node_2 -- node_2 -- relationship between node_2 and node_3 -- node_3....\"\n",
    "\n",
    "Here is the graph:\n",
    "\n",
    "{chemins}\n",
    "\n",
    "Make sure to incorporate EACH of the concepts in the knowledge graph in your response. \n",
    "\n",
    "Do not add any introductory phrases. First, define each term in the knowledge graph and then, secondly, discuss each of the relationships, with context. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b58596",
   "metadata": {},
   "outputs": [],
   "source": [
    "definition = None\n",
    "standard = None\n",
    "if LLM == 1:\n",
    "    definition = client.chat.complete(\n",
    "     model=\"mistral-large-latest\",\n",
    "     messages=[\n",
    "         {\n",
    "             \"role\": \"user\",\n",
    "             \"content\": ontologist,\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    standard = definition.choices[0].message.content\n",
    "elif LLM == 2:\n",
    "    definition = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\", \n",
    "    contents= ontologist,\n",
    "    )\n",
    "    standard = definition.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64a930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scientist = f\"\"\"You are a sophisticated scientist trained in scientific research and innovation. \n",
    "    \n",
    "Given the following key concepts extracted from a comprehensive knowledge graph, your task is to synthesize a novel research hypothesis. Your response should not only demonstrate deep understanding and rational thinking but also explore imaginative and unconventional applications of these concepts. \n",
    "    \n",
    "Consider this list of nodes and relationships from a knowledge graph between \"{concept1}\" and \"{concept2}\". \\\n",
    "The format of the graph is \"node_1 -- relationship between node_1 and node_2 -- node_2 -- relationship between node_2 and node_3 -- node_3....\"\n",
    "\n",
    "Here is the graph:\n",
    "\n",
    "{chemins}\n",
    "\n",
    "{standard}Analyze the graph deeply and carefully, then craft a detailed research hypothesis that investigates a likely groundbreaking aspect that incorporates EACH of these concepts. Consider the implications of your hypothesis and predict the outcome or behavior that might result from this line of investigation. Your creativity in linking these concepts to address unsolved problems or propose new, unexplored areas of study, emergent or unexpected behaviors, will be highly valued.\n",
    "\n",
    "Be as quantitative as possible and include details such as numbers, sequences, or chemical formulas. Please structure your response in JSON format, with SEVEN keys: \n",
    "\n",
    "\"hypothesis\" clearly delineates the hypothesis at the basis for the proposed research question.\n",
    "\n",
    "\"outcome\" describes the expected findings or impact of the research. Be quantitative and include numbers, material properties, sequences, or chemical formula.\n",
    "\n",
    "\"mechanisms\" provides details about anticipated chemical, biological or physical behaviors. Be as specific as possible, across all scales from molecular to macroscale.\n",
    "\n",
    "\"design_principles\" should list out detailed design principles, focused on novel concepts and include a high level of detail. Be creative and give this a lot of thought, and be exhaustive in your response. \n",
    "\n",
    "\"unexpected_properties\" should predict unexpected properties of the new material or system. Include specific predictions, and explain the rationale behind these clearly using logic and reasoning. Think carefully.\n",
    "\n",
    "\"comparison\" should provide a detailed comparison with other materials, technologies or scientific concepts. Be detailed and quantitative. \n",
    "\n",
    "\"novelty\" should discuss novel aspects of the proposed idea, specifically highlighting how this advances over existing knowledge and technology. \n",
    "\n",
    "Ensure your scientific hypothesis is both innovative and grounded in logical reasoning, capable of advancing our understanding or application of the concepts provided.\n",
    "\n",
    "Here is an example structure for your response, in JSON format:\n",
    "\n",
    "{{\n",
    "  \"hypothesis\": \"...\",\n",
    "  \"outcome\": \"...\",\n",
    "  \"mechanisms\": \"...\",\n",
    "  \"design_principles\": \"...\",\n",
    "  \"unexpected_properties\": \"...\",\n",
    "  \"comparison\": \"...\",\n",
    "  \"novelty\": \"...\",\n",
    "}}\n",
    "\n",
    "Remember, the value of your response is as scientific discovery, new avenues of scientific inquiry and potential technological breakthroughs, with details and solid reasoning.\n",
    "\n",
    "Make sure to incorporate EACH of the concepts in the knowledge graph in your response. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9642a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_response = None\n",
    "sortie = None\n",
    "if LLM == 1:\n",
    "    chat_response = client.chat.complete(\n",
    "     model=\"mistral-large-latest\",\n",
    "     messages=[\n",
    "         {\n",
    "             \"role\": \"user\",\n",
    "             \"content\": Scientist,\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    sortie = definition.choices[0].message.content\n",
    "elif LLM == 2:\n",
    "    chat_response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\", \n",
    "    contents= Scientist,\n",
    "    )\n",
    "    sortie = definition.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b35ac3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91680e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sortie)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sciagents-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
